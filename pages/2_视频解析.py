import cv2
import numpy as np
import base64
import requests
import tqdm
from PIL import Image
import io
import streamlit as st

# ---------------------- 1. å…±äº«é…ç½®ï¼ˆAPIå¯†é’¥+é¢œè‰²åŒæ­¥ï¼‰----------------------
API_KEY = "ms-9f99616d-d3cf-4783-922a-1ed9599fec3a"  # å·²é¢„è®¾ä½ çš„é­”æ­APIå¯†é’¥ï¼Œæ— éœ€ä¿®æ”¹
COLOR_SCHEMES = [
    {"bg": "#121212", "card": "#1E1E1E", "btn": "#8B5CF6", "accent": "#8B5CF6"},
    {"bg": "#1E1E2E", "card": "#2D2D44", "btn": "#6366F1", "accent": "#6366F1"},
    {"bg": "#1A1E3B", "card": "#2A2F55", "btn": "#3B82F6", "accent": "#3B82F6"},
    {"bg": "#2A1B3D", "card": "#3D2B5C", "btn": "#A855F7", "accent": "#A855F7"},
    {"bg": "#1B3B2A", "card": "#2B5C45", "btn": "#22C55E", "accent": "#22C55E"}
]
current_color = COLOR_SCHEMES[st.session_state.get("color_idx", 0)]

# ---------------------- 2. ç•Œé¢æ ·å¼ï¼ˆä¸å›¾ç‰‡é¡µåŒæ­¥ï¼‰----------------------
st.markdown(f"""
    <style>
        .stApp {{background-color: {current_color["bg"]}; color: #E0E0E0;}}
        .func-card {{
            background-color: {current_color["card"]};
            border-radius: 20px;
            padding: 20px;
            margin: 10px 0;
            border: 1px solid #333;
        }}
        .stButton > button {{
            background-color: {current_color["btn"]};
            color: white;
            border-radius: 10px;
            padding: 8px 16px;
            border: none;
        }}
        .stButton > button:hover {{background-color: {current_color["accent"]};}}
        .stTextArea > div > textarea {{
            background-color: {current_color["card"]};
            color: #E0E0E0;
            border-radius: 10px;
            border: 1px solid #444;
        }}
        .stFileUploader > div > div {{
            background-color: {current_color["card"]};
            border-radius: 10px;
            border: 1px dashed #444;
        }}
    </style>
""", unsafe_allow_html=True)

# ---------------------- 3. æ ¸å¿ƒå·¥å…·å‡½æ•°ï¼ˆè§†é¢‘åˆ†æï¼‰----------------------
def video_to_keyframes(video_file):
    temp_video_path = "temp_video.mp4"
    with open(temp_video_path, "wb") as f:
        f.write(video_file.getbuffer())
    
    cap = cv2.VideoCapture(temp_video_path)
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    keyframes = []
    frame_interval = fps  # æ¯ç§’1å¸§
    
    with st.spinner(f"æå–å…³é”®å¸§ï¼ˆå…±{total_frames}å¸§ï¼‰..."):
        progress_bar = st.progress(0)
        frame_idx = 0
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            if frame_idx % frame_interval == 0:
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                frame_pil = Image.fromarray(frame_rgb)
                frame_pil.thumbnail((640, 360))
                keyframes.append(frame_pil)
            frame_idx += 1
            progress_bar.progress(min(frame_idx / total_frames, 1.0))
    
    cap.release()
    return keyframes, fps

def image_to_base64(image):
    img_byte_arr = io.BytesIO()
    image.save(img_byte_arr, format="JPEG")
    return base64.b64encode(img_byte_arr.getvalue()).decode("utf-8")

def analyze_video(video_file):
    # æå–å…³é”®å¸§
    keyframes, fps = video_to_keyframes(video_file)
    if len(keyframes) == 0:
        return "è§†é¢‘å¸§æå–å¤±è´¥ï¼Œè¯·æ›´æ¢è§†é¢‘æ–‡ä»¶"
    
    # å…³é”®å¸§è½¬Base64
    base64_frames = [image_to_base64(frame) for frame in keyframes]
    
    # è°ƒç”¨APIåˆ†æ
    url = "https://api-inference.modelscope.cn/v1/chat/completions"
    headers = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}
    payload = {
        "model": "Qwen/Qwen2.5-VL-72B-Instruct",
        "messages": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": f"""åˆ†æè§†é¢‘{len(base64_frames)}ä¸ªå…³é”®å¸§ï¼Œè¾“å‡ºï¼š
1. æ ¸å¿ƒä¸»ä½“ï¼šè´¯ç©¿å§‹ç»ˆçš„äººç‰©/ç‰©ä½“
2. ç”»é¢é£æ ¼ï¼šè‰ºæœ¯é£æ ¼+è‰²å½©åŸºè°ƒ
3. è¿é•œæ‰‹æ³•ï¼šç±»å‹+é€Ÿåº¦
4. åˆ†é•œå¤´ï¼šåˆ‡æ¢ç‚¹+æ—¶é•¿
5. åœºæ™¯è½¬æ¢ï¼šæ–¹å¼
åˆ†ç‚¹æ¸…æ™°ï¼Œå¯ç›´æ¥å‚è€ƒ"""}
                ] + [{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}} for b64 in base64_frames]
            }
        ],
        "max_tokens": 800,
        "temperature": 0.6
    }
    response = requests.post(url, headers=headers, json=payload, timeout=90)
    response.raise_for_status()
    return response.json()["choices"][0]["message"]["content"]

# ---------------------- 4. æ ¸å¿ƒåŠŸèƒ½å¸ƒå±€ï¼ˆä»…ä¸Šä¼ +åˆ†æ+ç»“æœï¼‰----------------------
st.title("ğŸ¬ è§†é¢‘å…¨ç»´åº¦åˆ†æ")

# 1. è§†é¢‘ä¸Šä¼ +åˆ†ææŒ‰é’®ï¼ˆåŠŸèƒ½å¡ç‰‡ï¼‰
with st.container():
    st.markdown('<div class="func-card">', unsafe_allow_html=True)
    uploaded_video = st.file_uploader("ä¸Šä¼ è§†é¢‘ï¼ˆMP4/AVI/MKVï¼Œâ‰¤200MBï¼‰", type=["mp4", "avi", "mkv"])
    if uploaded_video:
        video_size = round(uploaded_video.size / 1024 / 1024, 2)
        st.markdown(f"ğŸ“Š è§†é¢‘ä¿¡æ¯ï¼š{uploaded_video.name}ï¼ˆå¤§å°ï¼š{video_size}MBï¼‰")
    analyze_btn = st.button("ğŸ¯ å¼€å§‹è§†é¢‘åˆ†æ", type="primary")
    st.markdown('</div>', unsafe_allow_html=True)

# 2. ç»“æœå±•ç¤ºæ¡†ï¼ˆåŠŸèƒ½å¡ç‰‡ï¼‰
with st.container():
    st.markdown('<div class="func-card">', unsafe_allow_html=True)
    st.subheader("ğŸ“ åˆ†æç»“æœ")
    result_box = st.text_area("åˆ†æç»“æœå°†æ˜¾ç¤ºåœ¨è¿™é‡Œï¼ˆå¯ç›´æ¥å¤åˆ¶ï¼‰", height=300, disabled=True, key="video_result")
    
    if analyze_btn and uploaded_video:
        try:
            with st.spinner("åˆ†æä¸­...ï¼ˆçº¦10-20ç§’ï¼‰"):
                result = analyze_video(uploaded_video)
                st.text_area("âœ… åˆ†æå®Œæˆ", value=result, height=300, key="video_result_active")
        except Exception as e:
            st.error(f"åˆ†æå¤±è´¥ï¼š{str(e)}")
    st.markdown('</div>', unsafe_allow_html=True)
